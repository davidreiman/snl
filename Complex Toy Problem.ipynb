{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove top and right axis from plots\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Beta, Binomial, HalfCauchy, Normal, Pareto, Uniform\n",
    "from pyro.distributions.util import scalar_like\n",
    "from pyro.infer import MCMC, NUTS, Predictive\n",
    "from pyro.infer.mcmc.util import initialize_model, summary\n",
    "from pyro.util import ignore_experimental_warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lbi.models\n",
    "from lbi.nde import NeuralRatioEstimator, NeuralLikelihoodEstimator\n",
    "from lbi.sequential import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(parameter_set, **kwargs):\n",
    "    obs_dim = 8\n",
    "    \n",
    "    m_theta = parameter_set[:, :2]\n",
    "    s1 = parameter_set[:, 2].pow(2)    \n",
    "    s2 = parameter_set[:, 3].pow(2)\n",
    "    rho = torch.tanh(parameter_set[:, 4])\n",
    "    S_theta = [torch.stack([s1.pow(2), rho*s1*s2], dim=-1), \n",
    "               torch.stack([rho*s1*s2, s2.pow(2)], dim=-1)]\n",
    "    S_theta = torch.stack(S_theta, dim=-1)\n",
    "\n",
    "    # TODO: Speed this up\n",
    "    samples = []\n",
    "    for m_th, S_th in zip(m_theta, S_theta):\n",
    "        dist = torch.distributions.MultivariateNormal(m_th, S_th)\n",
    "        sample = dist.sample((obs_dim//2,)).flatten()\n",
    "        samples.append(sample)\n",
    "\n",
    "    return torch.stack(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dim = 5\n",
    "obs_dim = 8\n",
    "true_param = torch.tensor([[0.7, -2.9, -1., -0.9, 0.6]])\n",
    "observation = simulator(true_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make multivariate uniform prior distribution\n",
    "priors = torch.distributions.Independent(torch.distributions.Uniform(low=-3*torch.ones(param_dim), high=3*torch.ones(param_dim)), \n",
    "                                         reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [['Linear', obs_dim + param_dim, 64], ['SELU'], \n",
    "          ['Linear', 64, 64], ['SELU'], \n",
    "          ['Linear', 64, 1]]\n",
    "model = lbi.models.Classifier(layers=layers)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "nre = NeuralRatioEstimator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snre = Sequential(priors=priors, obs_data=observation, param_dim=param_dim, model=nre, optimizer=optimizer, \n",
    "                  simulator=simulator, \n",
    "                  n_rounds=10,\n",
    "                  sims_per_model=1,\n",
    "                  num_initial_samples=500,\n",
    "                  num_samples_per_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 425 samples. Validating on 75 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   7%|▋         | 21/300 [00:00, 209.57it/s, step size=3.23e-01, acc. prob=0.734]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 complete. Time elapsed: 0m 1s. Total time elapsed: 0m 1s.\n",
      "===============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 300/300 [00:02, 128.67it/s, step size=7.24e-02, acc. prob=0.850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1,275 samples. Validating on 225 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   3%|▎         | 9/300 [00:00, 59.72it/s, step size=3.82e-02, acc. prob=0.628]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 complete. Time elapsed: 0m 5s. Total time elapsed: 0m 6s.\n",
      "===============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 300/300 [00:01, 196.98it/s, step size=4.42e-01, acc. prob=0.582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 2,125 samples. Validating on 375 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   7%|▋         | 22/300 [00:00, 208.31it/s, step size=5.24e-02, acc. prob=0.708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3 complete. Time elapsed: 0m 7s. Total time elapsed: 0m 12s.\n",
      "===============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 300/300 [00:03, 77.07it/s, step size=2.48e-02, acc. prob=0.912] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 2,975 samples. Validating on 525 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   6%|▋         | 19/300 [00:00, 177.83it/s, step size=6.15e-02, acc. prob=0.723]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4 complete. Time elapsed: 0m 10s. Total time elapsed: 0m 23s.\n",
      "===============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 300/300 [00:02, 133.26it/s, step size=7.74e-02, acc. prob=0.854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 3,825 samples. Validating on 675 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   2%|▏         | 6/300 [00:00, 56.25it/s, step size=3.44e-02, acc. prob=0.567]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5 complete. Time elapsed: 0m 11s. Total time elapsed: 0m 33s.\n",
      "===============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 300/300 [00:02, 100.91it/s, step size=1.12e-01, acc. prob=0.857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 4,675 samples. Validating on 825 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   3%|▎         | 8/300 [00:00, 77.17it/s, step size=6.60e-02, acc. prob=0.655]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 6 complete. Time elapsed: 0m 14s. Total time elapsed: 0m 47s.\n",
      "===============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 300/300 [00:02, 147.69it/s, step size=1.11e-01, acc. prob=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 5,525 samples. Validating on 975 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   2%|▏         | 5/300 [00:00, 25.22it/s, step size=3.12e-03, acc. prob=0.398]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 7 complete. Time elapsed: 0m 15s. Total time elapsed: 1m 2s.\n",
      "===============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 300/300 [00:02, 144.84it/s, step size=2.21e-01, acc. prob=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 6,375 samples. Validating on 1,125 samples.\n"
     ]
    }
   ],
   "source": [
    "snre.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = snre.hmc(num_samples=200000, walker_steps=7500, burn_in=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(posterior_samples.numpy(), \n",
    "              range=[(-3, 3) for i in range(param_dim)], \n",
    "              truths=true_param[0].numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lbi.models.ConditionalFlow(dim=obs_dim, \n",
    "                                   context_dim=param_dim, \n",
    "                                   transform_type='autoregressive', \n",
    "                                   n_layers=1, \n",
    "                                   hidden_units=128,\n",
    "                                   n_blocks=2, \n",
    "                                   dropout=0., \n",
    "                                   use_batch_norm=False, \n",
    "                                   tails='linear', \n",
    "                                   tail_bound=5, \n",
    "                                   n_bins=10,\n",
    "                                   min_bin_height=1e-5, \n",
    "                                   min_bin_width=1e-5, \n",
    "                                   min_derivative=1e-5, \n",
    "                                   unconditional_transform=True,\n",
    "                                   encoder=None)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "nle = NeuralLikelihoodEstimator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snle = Sequential(priors=priors, obs_data=observation, param_dim=param_dim, model=nle, optimizer=optimizer, \n",
    "                  simulator=simulator, \n",
    "                  reset_every_round=True,\n",
    "                  n_rounds=10,\n",
    "                  sims_per_model=1,\n",
    "                  max_n_epochs=200,\n",
    "                  num_initial_samples=500,\n",
    "                  num_samples_per_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snle.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = snle.hmc(num_samples=200000, walker_steps=2500, burn_in=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(posterior_samples.numpy(), \n",
    "              range=[(-3, 3) for i in range(param_dim)], \n",
    "              truths=true_param[0].numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lbi",
   "language": "python",
   "name": "lbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
